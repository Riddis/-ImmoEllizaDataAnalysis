{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4774, 22)"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "# Build path to file\n",
    "# Selects current working directory\n",
    "cwd = Path.cwd()\n",
    "csv_path = 'data/dataframe.csv'\n",
    "csv_cleaned_path = 'output/dataframe_cleaned.csv'\n",
    "src_path = (cwd / csv_path).resolve()\n",
    "out_path = (cwd / csv_cleaned_path).resolve()\n",
    "\n",
    "# Read the csv\n",
    "csv = pd.read_csv(src_path, index_col=0)\n",
    "csv.shape\n",
    "\n",
    "# Removing unneeded data\n",
    "# dropping empty rows\n",
    "csv = csv.dropna(how='all')\n",
    "# dropping duplicates (if any)\n",
    "csv = csv.drop_duplicates()\n",
    "# Dropping house and appartment groups since they have no data\n",
    "csv = csv.drop(csv[(csv['property_type'] == 'HOUSE_GROUP') | (csv['property_type'] == 'APARTMENT_GROUP')].index)\n",
    "# Drop rows without a price property\n",
    "csv = csv.drop(csv[pd.isna(csv['price']) == True].index)\n",
    "# Drop rows with 0 rooms\n",
    "csv = csv.drop(csv[csv['number_rooms'] == 0].index)\n",
    "# Drop rows without a living area property\n",
    "csv = csv.drop(csv[pd.isna(csv['living_area']) == True].index)\n",
    "# Assuming that a NaN value or 0 means no kitchen installed, replacing the strings with integers\n",
    "# 0 = NOT_INSTALLED, 0.5 = SEMI_EQUIPPED, 1 = INSTALLED, 2 = HYPER_EQUIPPED\n",
    "csv['kitchen'] = csv['kitchen'].fillna('NOT_INSTALLED')\n",
    "csv['kitchen'] = csv['kitchen'].replace('0', 'NOT_INSTALLED')\n",
    "csv['kitchen'] = csv['kitchen'].replace(0, 'NOT_INSTALLED')\n",
    "\"\"\"csv['kitchen'] = csv['kitchen'].replace('USA_UNINSTALLED', 0)\n",
    "csv['kitchen'] = csv['kitchen'].replace('SEMI_EQUIPPED', 0.5)\n",
    "csv['kitchen'] = csv['kitchen'].replace('USA_SEMI_EQUIPPED', 0.5)\n",
    "csv['kitchen'] = csv['kitchen'].replace('INSTALLED', 1)\n",
    "csv['kitchen'] = csv['kitchen'].replace('USA_INSTALLED', 1)\n",
    "csv['kitchen'] = csv['kitchen'].replace('HYPER_EQUIPPED', 2)\n",
    "csv['kitchen'] = csv['kitchen'].replace('USA_HYPER_EQUIPPED', 2)\"\"\"\n",
    "# Filling empty values and changing true/false to 1/0\n",
    "csv['furnished'] = csv['furnished'].fillna(0)\n",
    "csv['furnished'] = csv['furnished'].replace(False, 0)\n",
    "csv['furnished'] = csv['furnished'].replace(True, 1)\n",
    "# Assuming that a NaN value,0 or -1 means no fireplace installed\n",
    "csv['fireplace'] = csv['fireplace'].fillna(0)\n",
    "csv['fireplace'] = csv['fireplace'].replace(-1, 0)\n",
    "# Filling empty values and changing true/false to 1/0\n",
    "csv['terrace'] = csv['terrace'].fillna(0)\n",
    "csv['terrace'] = csv['terrace'].replace(False, 0)\n",
    "csv['terrace'] = csv['terrace'].replace(True, 1)\n",
    "# Assuming the surface area = living area in case of apartments\n",
    "to_replace = csv[((csv['surface_land'] == 'UNKNOWN')|(pd.isna(csv['surface_land']) == True)) & (csv['property_type'] == 'APARTMENT')]\n",
    "to_replace = to_replace.reset_index()\n",
    "# Looping through rows to replace the values\n",
    "for index, row in to_replace.iterrows():\n",
    "    csv.loc[row['index'], 'surface_land'] = row['living_area']\n",
    "# Dropping rows with no surface area \n",
    "csv = csv.drop(csv[(csv['surface_land'] == 'UNKNOWN') | (pd.isna(csv['surface_land']) == True) | (csv['surface_land'] == 0)].index)\n",
    "# Dropping rows with no facade info\n",
    "csv = csv.drop(csv[(csv['number_facades'] == 'UNKNOWN') | (pd.isna(csv['number_facades']) == True)].index)\n",
    "# Filling empty values and changing true/false to 1/0\n",
    "csv['swimming_pool'] = csv['swimming_pool'].fillna(0)\n",
    "csv['swimming_pool'] = csv['swimming_pool'].replace(False, 0)\n",
    "csv['swimming_pool'] = csv['swimming_pool'].replace(True, 1)\n",
    "csv = csv.drop(csv[(csv['building_state'] == 'UNKNOWN') | (pd.isna(csv['building_state']) == True)].index)\n",
    "\n",
    "# If terrace = 1 but no terrace_area present, drop the row\n",
    "csv = csv.drop(csv[(csv['terrace'] == 1) & (pd.isna(csv['terrace_area']) == True)].index)\n",
    "# Filling empty values and changing true/false to 1/0\n",
    "csv['terrace_area'] = csv['terrace_area'].fillna(0)\n",
    "# If garden = 1 but no garden_area present, drop the row\n",
    "csv = csv.drop(csv[(csv['garden'] == 1) & (pd.isna(csv['garden_area']) == True)].index)\n",
    "# No garden, filling empty values\n",
    "csv['garden'] = csv['garden'].fillna(0)\n",
    "csv['garden'] = csv['garden'].replace(False, 0)\n",
    "csv['garden'] = csv['garden'].replace(True, 1)\n",
    "csv['garden_area'] = csv['garden_area'].fillna(0)\n",
    "\n",
    "# Change strings to floats in certain columns\n",
    "csv = csv.drop(csv[(csv['surface_land'] == 0)].index)\n",
    "csv['surface_land']=csv['surface_land'].astype(\"float\")\n",
    "csv['number_facades']=csv['number_facades'].astype(\"float\")\n",
    "csv = csv.drop(csv[csv['zip_code'] == 'UNKNOWN'].index)\n",
    "csv = csv.drop(csv[pd.isna(csv['region']) == True].index)\n",
    "csv = csv.drop(csv[pd.isna(csv['province']) == True].index)\n",
    "csv['zip_code']=csv['zip_code'].astype(\"str\")\n",
    "csv['ppm'] = csv['price']/csv['surface_land']\n",
    "# Removing zipcodes that are not 4 numbers\n",
    "patternDel = \"\\b[0-9]\\{4\\}\\b\"\n",
    "filter = csv['zip_code'].str.contains(patternDel)\n",
    "csv = csv[~filter]\n",
    "# If we have less than 3 occurences, zipcode will be changed to 'other' so we don't overfit\n",
    "filter = csv['zip_code'].value_counts()\n",
    "csv['zip_code'] = np.where(csv['zip_code'].isin(filter.index[filter >= 4]), csv['zip_code'], 'other')\n",
    "# Removing outliers\n",
    "cols = ['price', 'number_rooms', 'living_area',\n",
    "       'furnished', 'fireplace', 'terrace', 'terrace_area', 'garden',\n",
    "       'garden_area', 'surface_land', 'number_facades', 'swimming_pool'] # one or more\n",
    "Q1 = csv[cols].quantile(0.25)\n",
    "Q3 = csv[cols].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "csv = csv[~((csv[cols] < (Q1 - 1.5 * IQR)) |(csv[cols] > (Q3 + 1.5 * IQR))).any(axis=1)]\n",
    "\n",
    "# Saves cleaned up csv to 'data/dataframe_cleaned.csv'\n",
    "csv.to_csv(out_path)\n",
    "csv.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(n):\n",
    "    if n == 'other':\n",
    "        return 'other'\n",
    "    else:\n",
    "        return str(int(int(n)/100))\n",
    "csv[\"digit\"]=csv[\"zip_code\"].agg(convert)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4774, 98)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "x = csv[['number_rooms', 'living_area',\n",
    "       'terrace', 'terrace_area', 'garden',\n",
    "       'garden_area', 'surface_land', 'number_facades',\n",
    "       'property_type', 'building_state', 'kitchen', 'region', 'digit']]\n",
    "\n",
    "x = pd.get_dummies(data=x, drop_first=True)\n",
    "X = x.to_numpy()\n",
    "y = csv['price'].to_numpy()\n",
    "\n",
    "print(X.shape)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=123)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score (regressor, X_train, X_test, y_train, y_test):\n",
    "    score_train = regressor.score(X_train, y_train)\n",
    "    score_test = regressor.score(X_test, y_test)\n",
    "\n",
    "    # Get the root mean squared error\n",
    "    y_pred = regressor.predict(X_test)\n",
    "    #rmse = mean_squared_error(y_true=y_test, y_pred=y_pred, squared=False)\n",
    "    rmse= np.sqrt(mean_squared_error(y_true=y_test, y_pred=y_pred))\n",
    "\n",
    "    u = ((y_test - y_pred)**2).sum()\n",
    "    v = ((y_test - y.mean())**2).sum()\n",
    "    coef_determination = 1 - u/v\n",
    "\n",
    "    print(f\"score train:{score_train}\")\n",
    "    print(f\"score test:{score_test}\")\n",
    "    print(f\"rmse:{rmse}\")\n",
    "    print(f\"coef_determination:{coef_determination}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score train:0.7200823716194424\n",
      "score test:0.6880006377098221\n",
      "rmse:94674.7084296804\n",
      "coef_determination:0.6880574910104393\n"
     ]
    }
   ],
   "source": [
    "regressor = LinearRegression()\n",
    "regressor.fit(X_train, y_train)\n",
    "\n",
    "score(regressor, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: zijn er variabelen met extreme coefficienten?\n",
    "# TODO: welke zijn de hoogste predictions, hoe zien de X eruit daarvoor?\n",
    "# TODO: normaliseer numerical variabelen tussen 0-1 (StandardScaler())\n",
    "# TODO: zipcode minder granulair?\n",
    "dict_coef = {x.columns[i]: regressor.coef_[i] for i in range(len(x.columns))}\n",
    "dict_coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "734689.0855482789"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"np.quantile(y_pred, q=0.90)\n",
    "pd.DataFrame(y_pred).hist(bins=10)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ridd\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:725: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Criterion: entropy\n",
      "Best max_depth: 12\n",
      "Best Number Of Components: 98\n",
      "\n",
      "DecisionTreeClassifier(criterion='entropy', max_depth=12)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier\n",
    "from sklearn import decomposition\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\"\"\"\n",
    "std_slc = StandardScaler()\n",
    "pca = decomposition.PCA()\n",
    "dec_tree = DecisionTreeClassifier()\n",
    "\n",
    "pipe = Pipeline(steps=[('std_slc', std_slc),\n",
    "                           ('pca', pca),\n",
    "                           ('dec_tree', dec_tree)])\n",
    "\n",
    "n_components = list(range(1,X_train.shape[1]+1,1))\n",
    "criterion = ['gini', 'entropy']\n",
    "max_depth = [2,4,6,8,10,12]\n",
    "\n",
    "parameters = dict(pca__n_components=n_components,\n",
    "                      dec_tree__criterion=criterion,\n",
    "                      dec_tree__max_depth=max_depth)\n",
    "\n",
    "clf_GS = GridSearchCV(pipe, parameters)\n",
    "clf_GS.fit(X_train, y_train)\n",
    "\n",
    "print('Best Criterion:', clf_GS.best_estimator_.get_params()['dec_tree__criterion'])\n",
    "print('Best max_depth:', clf_GS.best_estimator_.get_params()['dec_tree__max_depth'])\n",
    "print('Best Number Of Components:', clf_GS.best_estimator_.get_params()['pca__n_components'])\n",
    "params = clf_GS.best_estimator_.get_params()['dec_tree']\n",
    "print(); print(params)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score train:0.027094972067039105\n",
      "score test:0.031825795644891124\n",
      "rmse:135263.57145613714\n",
      "coef_determination:0.36325094551473147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ridd\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:725: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.03852185225554657"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor = DecisionTreeClassifier(ccp_alpha=0.001, random_state=0)\n",
    "regressor.fit(X_train, y_train).tree_.node_count\n",
    "\n",
    "score(regressor, X_train, X_test, y_train, y_test)\n",
    "cross_val_score(regressor, X_test, y_test, cv = 5, scoring = 'accuracy').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score train:0.8360335195530726\n",
      "score test:0.09045226130653267\n",
      "rmse:142332.29749213735\n",
      "coef_determination:0.294960372451204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ridd\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:725: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.03852536830631834"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor = DecisionTreeClassifier(criterion='entropy', max_depth=12)\n",
    "regressor.fit(X_train, y_train)\n",
    "\n",
    "score(regressor, X_train, X_test, y_train, y_test)\n",
    "cross_val_score(regressor, X_test, y_test, cv = 5, scoring = 'accuracy').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score train:0.8955140520285985\n",
      "score test:0.7231510458472554\n",
      "rmse:89182.27909100034\n",
      "coef_determination:0.7232014939529838\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xg\n",
    "\n",
    "regressor = xg.XGBRegressor(objective ='reg:squarederror', n_estimators = 50, seed = 123)\n",
    "regressor.fit(X_train, y_train)\n",
    "\n",
    "score(regressor, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score train:0.7172414777500633\n",
      "score test:0.6801913395316415\n",
      "rmse:95852.23267181792\n",
      "coef_determination:0.6802496158620164\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "regressor = SGDRegressor(max_iter=1000, tol=1e-3)\n",
    "regressor.fit(X_train, y_train)\n",
    "\n",
    "score(regressor, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score train:0.0611731843575419\n",
      "score test:0.038525963149078725\n",
      "rmse:108523.94056082008\n",
      "coef_determination:0.5978783265395025\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "regressor = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(5, 2), random_state=1, max_iter=1000)\n",
    "regressor.fit(X_train, y_train)\n",
    "\n",
    "score(regressor, X_train, X_test, y_train, y_test)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
